{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LAUNCH ME\n",
    "\n",
    "Following this file, you will be able to see our experiments and reproduce the result we shown in our project."
   ],
   "id": "a8c10e283dd16381"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Import",
   "id": "a3cf974a70032594"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T21:12:55.164621Z",
     "start_time": "2024-12-19T21:12:53.619682Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "# Our implemented parallelized class from the paper Dictionary Learning for Sparse Coding\n",
    "from src import DictionaryAlgoParallel \n",
    "\n",
    "# This function will import the dataset we need\n",
    "from src import get_boat_data, get_instruments_data, get_berekley_data_loaders \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I. Boat dataset",
   "id": "41da3f455961f4dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I.1 Hyperparameters",
   "id": "eedd957bfd9a2ffb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets first import the dataset from kaggle and parse it.",
   "id": "fe522a3be05718a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:12:59.582071Z",
     "start_time": "2024-12-19T21:12:55.171425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src import plot_image_grid\n",
    "\n",
    "def rescale_patch(patch, new_size=(16,16)):\n",
    "    patch_uint8 = (patch * 255).clip(0, 255).astype(np.uint8) if patch.dtype != np.uint8 else patch\n",
    "    pil_img = Image.fromarray(patch_uint8)\n",
    "    downscaled_image = pil_img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    downscaled_np = np.array(downscaled_image)\n",
    "    return downscaled_np\n",
    "\n",
    "\n",
    "path_boat = kagglehub.dataset_download(\"rhammell/ships-in-satellite-imagery\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_boat)\n",
    "x,y_true, images, jsondata = get_boat_data(path_boat)\n",
    "\n",
    "x = np.array(list(map(rescale_patch, x)))"
   ],
   "id": "ddb33410c1ca95dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/antoine/.cache/kagglehub/datasets/rhammell/ships-in-satellite-imagery/versions/9\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have our dataset, we can check what it contains.",
   "id": "9c89b1872d077e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocessing(datas):\n",
    "    \"\"\"\n",
    "    Flatten our data.\n",
    "    :param datas: (n_samples, n_rows, n_cols, n_channels)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    n_samples, n_rows, n_cols, n_channels = datas.shape\n",
    "    datas = datas.reshape(n_samples, -1) / 255\n",
    "    preprocessed = datas\n",
    "    infos = {\"shape\" : (n_rows, n_cols)}\n",
    "    return  preprocessed, infos\n",
    "\n",
    "def postprocessing(datas, infos, ):\n",
    "    \"\"\"\n",
    "    Unflatten our data to reconstruct our patch.\n",
    "    \"\"\"\n",
    "    n_rows, n_cols = infos[\"shape\"]\n",
    "    results = datas\n",
    "    results = results.reshape(len(datas), n_rows, n_cols, 3, order=\"C\").clip(0,1)\n",
    "    return results\n",
    "\n",
    "x_boat = x[y_true == 1.]\n",
    "x_background = x[y_true == 0.]\n",
    "x_background_preprocessing, infos_background_preprocessing = preprocessing(x_background)\n",
    "x_boat_preprocessing, infos_boat_preprocessing = preprocessing(x_boat)\n",
    "\n",
    "print(\" training data shape\", x_background_preprocessing.shape)\n",
    "print(\" boat (not used in training) data shape\", x_boat_preprocessing.shape)\n",
    "\n"
   ],
   "id": "228270d978983999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_image_grid(x_boat, 2, figsize = (2,2))",
   "id": "b1d7dbaf56899490"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_image_grid(x_background, 2, figsize = (2,2))",
   "id": "28483224e3d59fd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now train our Dictionary using our background preprocessed data",
   "id": "28a36e67e9a88364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_trained_dico():\n",
    "    m = patch_size[0] * patch_size[1]*3\n",
    "    nb_atoms = 30\n",
    "    dict_learner = DictionaryAlgoParallel(m=m, k=nb_atoms, lbd=1e-2, dic_update_steps=2, use_cuda=False, dico_update=\"quick_update\", n_jobs=-1, verbose=True) # Initialize our python class containing our training logic\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    from itertools import cycle\n",
    "    class FiniteGenerator:\n",
    "        def __init__(self, iterable, nb_elt,  batch_size = 8):\n",
    "            self.iterable = iterable\n",
    "            self.nb_elt = nb_elt\n",
    "            self.batch_size = batch_size\n",
    "        def __len__(self):\n",
    "            return self.nb_elt\n",
    "        def __iter__(self,):\n",
    "            infinite_loader = cycle(self.iterable)          \n",
    "            for k in tqdm(range(self.nb_elt // self.batch_size)):\n",
    "                data = np.array([next(infinite_loader) for _ in range(self.batch_size)])\n",
    "                yield torch.from_numpy(data).float()\n",
    "                \n",
    "    x_training = FiniteGenerator(x_background_preprocessing, 4*len(x_boat_preprocessing), batch_size=32)\n",
    "    dict_learner.D = torch.tensor(torch.from_numpy(x_background_preprocessing[:nb_atoms].T), dtype=torch.float)\n",
    "    dict_learner.D.to(dict_learner.device)\n",
    "    dict_learner.fit(x_training)\n",
    "    return dict_learner"
   ],
   "id": "bf8277680eb53b65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## II. Instrument dataset",
   "id": "143ea1801bc89a54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "path_instrument = kagglehub.dataset_download(\"soumendraprasad/musical-instruments-sound-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_instrument)\n",
    "\n",
    "Ys, sampling_rates, files = get_instruments_data(path_instrument)\n",
    "\n",
    "def to_mono(s):\n",
    "    if len(s.shape) == 2:  # Stereo signal\n",
    "        return np.mean(s, axis=1)  # Average the two channels to get mono\n",
    "    return s\n",
    "\n",
    "signals = list(map(to_mono, Ys))"
   ],
   "id": "c18e0efbc1ede17e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## III Berkeley image dataset",
   "id": "2310a0249d0f868c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.1 Hyperparameters\n",
   "id": "f8a3176ccc775034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "patch_size = (12,12)\n",
    "batch_size = ..."
   ],
   "id": "aec9824ad997832d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.2 Import dataset\n",
   "id": "27b5e1700e015408"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "path_berkeley = kagglehub.dataset_download(\"balraj98/berkeley-segmentation-dataset-500-bsds500\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_berkeley)\n",
    "\n",
    "get_berekley_data_loaders(\"berkeley\",  patch_size=patch_size, patches_per_image=5, batch_size=batch_size, norm_type=NormalizationType.ZSCORE)"
   ],
   "id": "e247de1f0533e698"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
