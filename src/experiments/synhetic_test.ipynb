{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:50:07.492061Z",
     "start_time": "2024-12-15T13:50:07.488709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "from src.dataset.dataloaders import get_dataset\n",
    "from src.dictionary.basic_dictionary_learning import base_algo1, batched_algo1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4e7890d99de2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:50:07.554029Z",
     "start_time": "2024-12-15T13:50:07.538694Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_synthetic(dictionary, nb_elt_per_comb_lin, n, coef_generator = None):\n",
    "    \"\"\"\n",
    "    Generate a synthetic dataset by selecting elements from a dictionary (matrix),\n",
    "    linearly combining them, and creating a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - dictionary (np.ndarray): A matrix of shape (nb_atom, d) where each row is an atom and columns are features.\n",
    "    - nb_elt_per_comb_lin (int): The number of elements to select for each linear combination.\n",
    "    - n (int): The number of synthetic data points to generate.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A synthetic dataset of shape (n, d), where each row is a result of linear combinations of selected atoms.\n",
    "    - list: A list of indices used to create the dataset.\n",
    "    \"\"\"\n",
    "    if coef_generator is None:\n",
    "        coef_generator = np.random.randn\n",
    "    if not isinstance(dictionary, np.ndarray):\n",
    "        raise ValueError(\"The dictionary parameter must be a numpy array.\")\n",
    "    if len(dictionary.shape) != 2:\n",
    "        raise ValueError(\"The dictionary must be a 2D matrix.\")\n",
    "    if nb_elt_per_comb_lin <= 0:\n",
    "        raise ValueError(\"nb_elt_per_comb_lin must be greater than 0.\")\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be greater than 0.\")\n",
    "    \n",
    "    nb_atom, d = dictionary.shape\n",
    "    if nb_atom < nb_elt_per_comb_lin:\n",
    "        raise ValueError(\"nb_elt_per_comb_lin cannot be greater than the number of atoms in the dictionary.\")\n",
    "    \n",
    "    synthetic_data = []\n",
    "    combinations_used = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Randomly select atoms for linear combination\n",
    "        selected_indices = random.sample(range(nb_atom), nb_elt_per_comb_lin)\n",
    "        \n",
    "    \n",
    "        # Generate random coefficients for the linear combination\n",
    "        coefficients = coef_generator(nb_elt_per_comb_lin)\n",
    "    \n",
    "        combinaison = list(zip(selected_indices, map( lambda x : float(x), coefficients)))\n",
    "        combinations_used.append(combinaison)\n",
    "        # Create the linear combination of selected atoms\n",
    "        combined_data = sum(coef * dictionary[idx] for idx,coef in combinaison)\n",
    "    \n",
    "        # Add the combined data to the synthetic dataset\n",
    "        synthetic_data.append(combined_data)\n",
    "    \n",
    "    return np.array(synthetic_data), combinations_used\n",
    "    \n",
    "\n",
    "dico = np.array([[1,0,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0,0]])\n",
    "data = generate_synthetic(dico, 2, 10)\n",
    "def train_loader():\n",
    "    while True:\n",
    "        data = torch.from_numpy(generate_synthetic(dico, 2, 2)[0])\n",
    "        #print(data.shape)\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e0dbe802fde9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:50:21.756251Z",
     "start_time": "2024-12-15T13:50:07.619180Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:14<00:00, 707.50it/s]\n"
     ]
    }
   ],
   "source": [
    "m = dico.shape[-1]\n",
    "k = 3\n",
    "D = batched_algo1(train_loader(), m=m, k=k, lbd=0, tmax=int(1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194b1e6ed5725cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:51:27.845659Z",
     "start_time": "2024-12-15T13:51:27.840941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8818, -0.0710, -0.8005],\n",
      "        [ 0.3758,  0.9316,  0.5376],\n",
      "        [ 0.1344, -0.1515, -0.0079],\n",
      "        [ 0.0335, -0.1050,  0.0660],\n",
      "        [ 0.0170, -0.0975,  0.0780],\n",
      "        [ 0.1591, -0.1629, -0.0259],\n",
      "        [ 0.0402, -0.1082,  0.0610],\n",
      "        [ 0.1756, -0.1705, -0.0381],\n",
      "        [ 0.0624, -0.1184,  0.0448]])\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c6172045a1072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
